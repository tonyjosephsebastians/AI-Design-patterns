{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNxIH3RXR1ZvNZYwZ1kkYX3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tonyjosephsebastians/AI-Design-patterns/blob/main/GROUP_2_%E2%80%94_Duplicate_Requests_%26_Retries_Break_the_System_(Correctness_%2B_Cost_Safety).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Goal: Safe retries without duplicate work, inconsistent writes, or doubled token spend.\n",
        "\n",
        "Patterns covered:\n",
        "\n",
        "Command Pattern (GoF)\n",
        "\n",
        "Idempotent Command Pattern\n",
        "\n",
        "Request Deduplication Pattern\n",
        "\n",
        "Content Hashing Pattern\n",
        "\n",
        "Singleton (GoF — config/clients only)\n",
        "\n",
        "Concurrency (why DB/Redis uniqueness is required)"
      ],
      "metadata": {
        "id": "XZ_i633ealux"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json, hashlib, time, random, threading\n",
        "from dataclasses import dataclass, asdict\n",
        "from typing import Optional, Dict, Tuple\n"
      ],
      "metadata": {
        "id": "Nl1p0Qw5atsO"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "JOBS: Dict[str, dict] = {}\n",
        "TOKEN_SPEND = 0\n",
        "\n",
        "def fake_llm_call(payload: dict) -> dict:\n",
        "    \"\"\"Simulate an LLM call with token spend.\"\"\"\n",
        "    global TOKEN_SPEND\n",
        "    tokens = 1200 + random.randint(-150, 200)\n",
        "    TOKEN_SPEND += tokens\n",
        "    return {\"output\": \"analysis-result\", \"tokens\": tokens, \"payload\": payload}\n",
        "\n",
        "def create_job(payload: dict) -> str:\n",
        "    job_id = f\"job_{int(time.time()*1000)}_{random.randint(100,999)}\"\n",
        "    JOBS[job_id] = {\"status\": \"RUNNING\", \"payload\": payload, \"result\": None}\n",
        "    # simulate doing the work right away\n",
        "    result = fake_llm_call(payload)\n",
        "    JOBS[job_id][\"status\"] = \"SUCCEEDED\"\n",
        "    JOBS[job_id][\"result\"] = result\n",
        "    return job_id\n",
        "\n",
        "def baseline_endpoint(payload: dict) -> dict:\n",
        "    \"\"\"What many systems accidentally do: create new work every time.\"\"\"\n",
        "    job_id = create_job(payload)\n",
        "    return {\"job_id\": job_id, \"status\": JOBS[job_id][\"status\"]}\n",
        "\n",
        "payload = {\"user_id\":\"tony\", \"doc_id\":\"pdf123\", \"operation\":\"extract_clauses_v1\", \"params\":{\"lang\":\"en\"}}\n",
        "\n",
        "TOKEN_SPEND = 0\n",
        "JOBS.clear()\n",
        "\n",
        "r1 = baseline_endpoint(payload)\n",
        "r2 = baseline_endpoint(payload)  # retry!\n",
        "print(\"1st:\", r1)\n",
        "print(\"2nd:\", r2)\n",
        "print(\"Jobs created:\", len(JOBS))\n",
        "print(\"Token spend:\", TOKEN_SPEND)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsrng8xXawuC",
        "outputId": "c2c2d531-8256-41cb-d205-e62d476268f5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1st: {'job_id': 'job_1770607600876_584', 'status': 'SUCCEEDED'}\n",
            "2nd: {'job_id': 'job_1770607600876_733', 'status': 'SUCCEEDED'}\n",
            "Jobs created: 2\n",
            "Token spend: 2453\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Command Pattern (GoF): make the action a first-class object"
      ],
      "metadata": {
        "id": "XZaEqzXXcCP1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass(frozen=True)\n",
        "class AnalyzeDocumentCommand:\n",
        "    user_id: str\n",
        "    doc_id: str\n",
        "    operation: str\n",
        "    params: dict\n",
        "\n",
        "cmd = AnalyzeDocumentCommand(\n",
        "    user_id=\"tony\",\n",
        "    doc_id=\"pdf123\",\n",
        "    operation=\"extract_clauses_v1\",\n",
        "    params={\"lang\":\"en\"}\n",
        ")\n",
        "\n",
        "print(cmd)\n",
        "print(\"As dict:\", asdict(cmd))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7g77-uXwbyMI",
        "outputId": "36cd5ece-e58a-4163-ca66-8bd3165b9e88"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AnalyzeDocumentCommand(user_id='tony', doc_id='pdf123', operation='extract_clauses_v1', params={'lang': 'en'})\n",
            "As dict: {'user_id': 'tony', 'doc_id': 'pdf123', 'operation': 'extract_clauses_v1', 'params': {'lang': 'en'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Content Hashing Pattern: fingerprint the “work”"
      ],
      "metadata": {
        "id": "UI-_E9LtcXXZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def command_hash(cmd: AnalyzeDocumentCommand) -> str:\n",
        "    payload = asdict(cmd)\n",
        "    canonical = json.dumps(payload, sort_keys=True, separators=(\",\", \":\"))\n",
        "    return hashlib.sha256(canonical.encode(\"utf-8\")).hexdigest()\n",
        "\n",
        "h1 = command_hash(cmd)\n",
        "h2 = command_hash(cmd)\n",
        "print(\"Hash stable:\", h1 == h2)\n",
        "print(\"Hash:\", h1[:24], \"...\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChgLYkqWcJKm",
        "outputId": "835d1ff9-b611-4666-990c-cdbc6bb6b5ff"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hash stable: True\n",
            "Hash: d182f07ca44515165cd5e7b0 ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Include in hash:\n",
        "\n",
        "user_id (or tenant)\n",
        "\n",
        "doc_id (or file hash)\n",
        "\n",
        "operation version\n",
        "\n",
        "params that affect output\n",
        "\n",
        "Exclude from hash:\n",
        "\n",
        "timestamps\n",
        "\n",
        "request_id\n",
        "\n",
        "tracing headers"
      ],
      "metadata": {
        "id": "PS4OD3efceKl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Request Deduplication Pattern: reuse same job for same hash"
      ],
      "metadata": {
        "id": "SilBYNO5cia3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DEDUP_BY_HASH: Dict[Tuple[str,str], str] = {}  # (user_id, cmd_hash) -> job_id\n",
        "\n",
        "def dedup_endpoint(cmd: AnalyzeDocumentCommand) -> dict:\n",
        "    payload = asdict(cmd)\n",
        "    h = command_hash(cmd)\n",
        "    key = (cmd.user_id, h)\n",
        "\n",
        "    if key in DEDUP_BY_HASH:\n",
        "        job_id = DEDUP_BY_HASH[key]\n",
        "        return {\"job_id\": job_id, \"deduped\": True, \"status\": JOBS[job_id][\"status\"]}\n",
        "\n",
        "    job_id = create_job(payload)\n",
        "    DEDUP_BY_HASH[key] = job_id\n",
        "    return {\"job_id\": job_id, \"deduped\": False, \"status\": JOBS[job_id][\"status\"]}\n",
        "\n",
        "TOKEN_SPEND = 0\n",
        "JOBS.clear()\n",
        "DEDUP_BY_HASH.clear()\n",
        "\n",
        "r1 = dedup_endpoint(cmd)\n",
        "r2 = dedup_endpoint(cmd)  # retry!\n",
        "print(\"1st:\", r1)\n",
        "print(\"2nd:\", r2)\n",
        "print(\"Jobs created:\", len(JOBS))\n",
        "print(\"Token spend:\", TOKEN_SPEND)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJpFfNRTcbNX",
        "outputId": "8906290c-ee1b-4970-e293-ce1b6a1a157f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1st: {'job_id': 'job_1770607854070_320', 'deduped': False, 'status': 'SUCCEEDED'}\n",
            "2nd: {'job_id': 'job_1770607854070_320', 'deduped': True, 'status': 'SUCCEEDED'}\n",
            "Jobs created: 1\n",
            "Token spend: 1099\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "empotent Command Pattern: client defines “same intent”"
      ],
      "metadata": {
        "id": "bZk637xUdC7S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IDEMPOTENCY_MAP: Dict[Tuple[str,str], str] = {}  # (user_id, idem_key) -> job_id\n",
        "\n",
        "def idempotent_endpoint(cmd: AnalyzeDocumentCommand, idem_key: str) -> dict:\n",
        "    payload = asdict(cmd)\n",
        "    key = (cmd.user_id, idem_key)\n",
        "\n",
        "    if key in IDEMPOTENCY_MAP:\n",
        "        job_id = IDEMPOTENCY_MAP[key]\n",
        "        return {\"job_id\": job_id, \"deduped\": True, \"via\": \"idempotency_key\"}\n",
        "\n",
        "    job_id = create_job(payload)\n",
        "    IDEMPOTENCY_MAP[key] = job_id\n",
        "    return {\"job_id\": job_id, \"deduped\": False, \"via\": \"new_job\"}\n",
        "\n",
        "TOKEN_SPEND = 0\n",
        "JOBS.clear()\n",
        "IDEMPOTENCY_MAP.clear()\n",
        "\n",
        "print(idempotent_endpoint(cmd, \"abc-123\"))\n",
        "print(idempotent_endpoint(cmd, \"abc-123\"))       # retry => same job\n",
        "print(idempotent_endpoint(cmd, \"different-key\")) # new intent boundary => new job\n",
        "\n",
        "print(\"Jobs created:\", len(JOBS))\n",
        "print(\"Token spend:\", TOKEN_SPEND)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JcTdoguZdCvN",
        "outputId": "a6cb9f3a-7817-414a-99f9-0afd23c4aa8f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'job_id': 'job_1770607926320_917', 'deduped': False, 'via': 'new_job'}\n",
            "{'job_id': 'job_1770607926320_917', 'deduped': True, 'via': 'idempotency_key'}\n",
            "{'job_id': 'job_1770607926320_971', 'deduped': False, 'via': 'new_job'}\n",
            "Jobs created: 2\n",
            "Token spend: 2418\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 7 — Best practice: combine BOTH (key + hash fallback)"
      ],
      "metadata": {
        "id": "DeQM9Japdvsb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "“We do defense-in-depth: key first, hash fallback.”"
      ],
      "metadata": {
        "id": "tImjfhsjdz1X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DEDUP_HASH: Dict[Tuple[str,str], str] = {}\n",
        "DEDUP_IDEM: Dict[Tuple[str,str], str] = {}\n",
        "\n",
        "def best_practice_endpoint(cmd: AnalyzeDocumentCommand, idem_key: Optional[str] = None) -> dict:\n",
        "    payload = asdict(cmd)\n",
        "    h = command_hash(cmd)\n",
        "\n",
        "    # 1) Idempotency key path\n",
        "    if idem_key:\n",
        "        ikey = (cmd.user_id, idem_key)\n",
        "        if ikey in DEDUP_IDEM:\n",
        "            job_id = DEDUP_IDEM[ikey]\n",
        "            return {\"job_id\": job_id, \"deduped\": True, \"via\": \"idempotency_key\"}\n",
        "\n",
        "    # 2) Hash fallback path\n",
        "    hkey = (cmd.user_id, h)\n",
        "    if hkey in DEDUP_HASH:\n",
        "        job_id = DEDUP_HASH[hkey]\n",
        "        return {\"job_id\": job_id, \"deduped\": True, \"via\": \"command_hash\"}\n",
        "\n",
        "    # Create new\n",
        "    job_id = create_job(payload)\n",
        "    DEDUP_HASH[hkey] = job_id\n",
        "    if idem_key:\n",
        "        DEDUP_IDEM[(cmd.user_id, idem_key)] = job_id\n",
        "\n",
        "    return {\"job_id\": job_id, \"deduped\": False, \"via\": \"new_job\"}\n",
        "\n",
        "TOKEN_SPEND = 0\n",
        "JOBS.clear()\n",
        "DEDUP_HASH.clear()\n",
        "DEDUP_IDEM.clear()\n",
        "\n",
        "print(best_practice_endpoint(cmd, None))          # no idem\n",
        "print(best_practice_endpoint(cmd, None))          # retry => hash dedupe\n",
        "print(best_practice_endpoint(cmd, \"retry-001\"))   # idem maps too\n",
        "print(best_practice_endpoint(cmd, \"retry-001\"))   # retry => idem dedupe\n",
        "\n",
        "print(\"Jobs created:\", len(JOBS))\n",
        "print(\"Token spend:\", TOKEN_SPEND)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnyxMvR1dObV",
        "outputId": "8185ebe6-ea5a-41e4-cc32-460f01fb2512"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'job_id': 'job_1770608184110_228', 'deduped': False, 'via': 'new_job'}\n",
            "{'job_id': 'job_1770608184110_228', 'deduped': True, 'via': 'command_hash'}\n",
            "{'job_id': 'job_1770608184110_228', 'deduped': True, 'via': 'command_hash'}\n",
            "{'job_id': 'job_1770608184110_228', 'deduped': True, 'via': 'command_hash'}\n",
            "Jobs created: 1\n",
            "Token spend: 1095\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "race conditions (two requests at same time)\n",
        "\n",
        "Even perfect logic can fail without atomic guarantee."
      ],
      "metadata": {
        "id": "A9IqLoc0eTCf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TOKEN_SPEND = 0\n",
        "JOBS.clear()\n",
        "DEDUP_HASH.clear()\n",
        "DEDUP_IDEM.clear()\n",
        "\n",
        "def thread_task():\n",
        "    print(best_practice_endpoint(cmd, None))\n",
        "\n",
        "threads = [threading.Thread(target=thread_task) for _ in range(2)]\n",
        "for t in threads: t.start()\n",
        "for t in threads: t.join()\n",
        "\n",
        "print(\"Jobs created:\", len(JOBS))\n",
        "print(\"Token spend:\", TOKEN_SPEND)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6s0o6GR5eEPC",
        "outputId": "0c7511f2-e24c-4aa2-8f63-89032bc276e6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'job_id': 'job_1770608225100_542', 'deduped': False, 'via': 'new_job'}\n",
            "{'job_id': 'job_1770608225100_542', 'deduped': True, 'via': 'command_hash'}\n",
            "Jobs created: 1\n",
            "Token spend: 1369\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fix race with a lock (simulation of Redis SETNX / DB constraint)"
      ],
      "metadata": {
        "id": "-T63ALiCehCZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LOCK = threading.Lock()\n",
        "\n",
        "def locked_endpoint(cmd: AnalyzeDocumentCommand) -> dict:\n",
        "    payload = asdict(cmd)\n",
        "    h = command_hash(cmd)\n",
        "    hkey = (cmd.user_id, h)\n",
        "\n",
        "    with LOCK:  # simulate atomicity\n",
        "        if hkey in DEDUP_HASH:\n",
        "            job_id = DEDUP_HASH[hkey]\n",
        "            return {\"job_id\": job_id, \"deduped\": True, \"via\": \"atomic_lock\"}\n",
        "\n",
        "        job_id = create_job(payload)\n",
        "        DEDUP_HASH[hkey] = job_id\n",
        "        return {\"job_id\": job_id, \"deduped\": False, \"via\": \"atomic_lock\"}\n",
        "\n",
        "TOKEN_SPEND = 0\n",
        "JOBS.clear()\n",
        "DEDUP_HASH.clear()\n",
        "\n",
        "threads = [threading.Thread(target=lambda: print(locked_endpoint(cmd))) for _ in range(2)]\n",
        "for t in threads: t.start()\n",
        "for t in threads: t.join()\n",
        "\n",
        "print(\"Jobs created:\", len(JOBS))\n",
        "print(\"Token spend:\", TOKEN_SPEND)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjWk9i4teXPN",
        "outputId": "f86a52f4-aa81-4024-8e99-0c64aed4abf9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'job_id': 'job_1770608290729_807', 'deduped': False, 'via': 'atomic_lock'}\n",
            "{'job_id': 'job_1770608290729_807', 'deduped': True, 'via': 'atomic_lock'}\n",
            "Jobs created: 1\n",
            "Token spend: 1383\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Singleton Pattern (GoF): ONLY for config/clients"
      ],
      "metadata": {
        "id": "ezHvjI_-epw8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConfigSingleton:\n",
        "    _instance = None\n",
        "    def __new__(cls):\n",
        "        if cls._instance is None:\n",
        "            cls._instance = super().__new__(cls)\n",
        "            cls._instance.llm_model = \"gpt-5.2\"\n",
        "            cls._instance.timeout_s = 30\n",
        "        return cls._instance\n",
        "\n",
        "c1 = ConfigSingleton()\n",
        "c2 = ConfigSingleton()\n",
        "print(\"Same instance:\", c1 is c2)\n",
        "print(\"Model:\", c1.llm_model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfJ4qFsCenWn",
        "outputId": "c026d0b0-c2f3-45c7-864e-5117333b35f4"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Same instance: True\n",
            "Model: gpt-5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Good for: config, db client, redis client\n"
      ],
      "metadata": {
        "id": "TOkeywbve0_f"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IlsmPAqFeyUb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}